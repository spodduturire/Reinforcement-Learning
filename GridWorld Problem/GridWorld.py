# -*- coding: utf-8 -*-
"""RLHW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S87eSydZ5WBqHI0XedDlFyLOrzel9hpI
"""

import numpy as np

def go_up(current_state):
  return (current_state[0]-1, current_state[1])

def go_down(current_state):
  return (current_state[0]+1, current_state[1])

def go_left(current_state):
  return (current_state[0], current_state[1]-1)

def go_right(current_state):
  return (current_state[0], current_state[1]+1)

def get_reward(next_state, gold):
  if next_state == (0, 2):
    return gold
  if next_state == (4, 2):
    return -10
  if next_state == (4, 4):
    return 10
  return 0

def is_valid_state(current_state):
  return current_state[0] > -1 and current_state[0] < 5 and current_state[1] > -1 and current_state[1] < 5 and current_state != (2, 2) and current_state != (3, 2)

def add_to_dic(dic, state, current_state, p):
  if is_valid_state(state):
    if state in dic.keys():
      dic[state] += p
    else:
      dic[state] = p
  else:
    if current_state in dic.keys():
      dic[current_state] += p
    else:
      dic[current_state] = p

def get_transition_probs(dic, main_state, left_state, right_state, current_state):
    add_to_dic(dic, main_state, current_state, 0.8)
    add_to_dic(dic, left_state, current_state, 0.05)
    add_to_dic(dic, right_state, current_state, 0.05)
    if current_state in dic.keys():
        dic[current_state] += 0.10
    else:
      dic[current_state] = 0.10

def get_next_state_probs(current_state, action):
  dic = {}
  if action == 'AU':
    main_state = go_up(current_state)
    left_state = go_left(current_state)
    right_state = go_right(current_state)
    get_transition_probs(dic, main_state, left_state, right_state, current_state)

  if action == 'AD':
    main_state = go_down(current_state)
    left_state = go_right(current_state)
    right_state = go_left(current_state)
    get_transition_probs(dic, main_state, left_state, right_state, current_state)

  if action == 'AL':
    main_state = go_left(current_state)
    left_state = go_down(current_state)
    right_state = go_up(current_state)
    get_transition_probs(dic, main_state, left_state, right_state, current_state)

  if action == 'AR':
    main_state = go_right(current_state)
    left_state = go_up(current_state)
    right_state = go_down(current_state)
    get_transition_probs(dic, main_state, left_state, right_state, current_state)

  return dic

def get_max_action(current_state, prev_values, gamma, gold, terminal_states):
  max_action = ''
  max_action_value = float('-inf')
  if current_state in terminal_states:
    return 'G', 0
  for action in ['AU', 'AD', 'AL', 'AR']:
    a = get_next_state_probs(current_state, action)
    total = 0
    for key, value in a.items():
      total += (value*get_reward(key, gold)) + (value*gamma*prev_values[key])
    if total > max_action_value:
      max_action = action
      max_action_value = total
  return max_action, max_action_value

def arrow_representation(state_actions):
  dic = {'AU':'\u2191', 'AD':'\u2193', 'AL':'\u2190', 'AR':'\u2192', 'G':'G'}
  for i in range(len(state_actions)):
    for j in range(len(state_actions)):
      state_actions[i][j] = dic.get(state_actions[i][j], state_actions[i][j])
  return state_actions

def rounded_representation(state_values):
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      state_values[i][j] = round(state_values[i][j], 4)
  return state_values

#############################################################################################
#################################### Q1 #####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.9
gold = 0
terminal_states = [(4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print("Iterations ->"+str(counter))

#############################################################################################
#################################### Q2 #####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.25
gold = 0
terminal_states = [(4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print("Iterations ->"+str(counter))

#############################################################################################
#################################### Q3 #####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.9
gold = 5
terminal_states = [(4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print("Iterations ->"+str(counter))

#############################################################################################
#################################### Q4a ####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.9
gold = 5
terminal_states = [(0, 2), (4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print("Iterations ->"+str(counter))

#############################################################################################
#################################### Q4c ####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.914
gold = 5
terminal_states = [(0, 2), (4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print("Iterations ->"+str(counter))

#############################################################################################
#################################### Q5 #####################################################
#############################################################################################

state_values = np.zeros((5, 5))
state_actions = np.random.choice(['AU', 'AD', 'AL', 'AR'], size=(5, 5), p=[0.25, 0.25, 0.25, 0.25])
state_actions[(2, 2)] = ' '
state_actions[(3, 2)] = ' '
gamma = 0.9
gold = 4.4
terminal_states = [(0, 2), (4, 4)]

counter = 0
while True:
  delta = 0
  counter += 1
  next_state_values = np.zeros((5, 5))
  for i in range(len(state_values)):
    for j in range(len(state_values)):
      if is_valid_state((i, j)):
        temp = state_values[i][j]
        state_actions[i][j], next_state_values[i][j] = get_max_action((i, j), state_values, gamma, gold, terminal_states)
        delta = max(delta, abs(temp - next_state_values[i][j]))
  if delta < 0.0001:
    break
  state_values = next_state_values.copy()
print(rounded_representation(state_values))
print(arrow_representation(state_actions))
print(counter)